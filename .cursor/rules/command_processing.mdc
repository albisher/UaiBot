---
description: 
globs: 
alwaysApply: true
---
- AI Model Architecture:
  * Use BaseAIModel interface for all model implementations
  * Support multiple AI providers through standardized interfaces
  * Allow easy switching between different models with validation
  * Maintain consistent interface through BaseAIModel
  * Design for future model upgrades/changes
  * Support model-specific optimizations through model_params

- Current Implementation:
  * Supports both Google AI and Ollama models
  * Each model implements BaseAIModel interface
  * Model-specific code isolated in dedicated classes
  * Consistent parameter handling and response format
  * Robust error handling and fallback mechanisms
  * Easy addition of new models through interface implementation
  * Currently no regex code is allowed before the AI model reply

- Command Processing:
  * Follow the command processing pipeline
  * Implement proper error handling at each stage
  * Maintain clear separation between interpretation and execution
  * Document all command patterns
  * Ensure proper validation of model responses
  * Support model-agnostic command patterns
  * Use standardized response format across all models

- Model Response Format:
  * All models must return responses in the following format:
    {
      "command": str,  # The processed command
      "confidence": float,  # Confidence score (0-1)
      "model": str,  # Model name
      "type": str,  # Response type (e.g., "shell")
      "parameters": dict  # Additional parameters
    }
  * Consistent error handling and reporting
  * Proper validation of response format
  * Support for model-specific metadata

# Command Processing Rules

## Command Pipeline
1. Interpretation Stage
   - Natural language processing
   - Intent extraction
   - Command structure validation
   - Use dataclasses for command objects
   - Type-safe command representation

2. Validation Stage
   - Safety level assessment
   - Permission checks
   - Context validation
   - Resource availability
   - Use enums for safety levels

3. Execution Stage
   - Command routing
   - Shell/system interaction
   - Output capture
   - Error handling
   - Event emission

4. Post-processing Stage
   - Output formatting
   - Result storage
   - Logging
   - Event handling
   - Response generation

## Command Objects
```python
@dataclass
class Command:
    text: str
    intent: str
    safety_level: SafetyLevel
    parameters: Dict[str, Any]
    metadata: Dict[str, Any]

@dataclass
class CommandResult:
    success: bool
    output: str
    error: Optional[str]
    metadata: Dict[str, Any]
```

## Event System
- Use observer pattern for command events
- Emit events for each pipeline stage
- Allow event handlers to modify behavior
- Support async event processing
- Maintain event history

## Error Handling
- Use custom exception hierarchy
- Provide detailed error information
- Support error recovery
- Log all errors
- Return structured error responses

## Best Practices
- Use type hints for all methods
- Implement command validation
- Support command chaining
- Enable command cancellation
- Provide command progress updates
